{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df5a3bd3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_iris\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MinMaxScaler\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pyplot \u001b[38;5;28;01mas\u001b[39;00m plt\n\u001b[1;32m      5\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267148c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# more readable visuals \n",
    "large = 22; med = 16; small = 10\n",
    "params = {'axes.titlesize': large,\n",
    "          'legend.fontsize': med,\n",
    "          'figure.figsize': (16, 10),\n",
    "          'axes.labelsize': med,\n",
    "          'axes.titlesize': med,\n",
    "          'axes.linewidth': 2,\n",
    "          'xtick.labelsize': med,\n",
    "          'ytick.labelsize': med,\n",
    "          'figure.titlesize': large}\n",
    "plt.style.use('seaborn-white')\n",
    "plt.rcParams.update(params)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3f7481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data # predictor\n",
    "y = iris.target #response\n",
    "\n",
    "print('The predictor variable shape: ', X.shape)\n",
    "print('The response variable shape: ', y.shape)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43e7a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X_scaled.shape[1] #input shape\n",
    "output_dim = X_scaled.shape[1]\n",
    "encoding_dim = 2 # encoding dimension - #neurons for the dense layers\n",
    "optimizer = 'adam'\n",
    "loss = 'mse'\n",
    "\n",
    "input_layer = tf.keras.Input(shape=(input_dim,), name='input') # input layer\n",
    "encoding_layer = tf.keras.layers.Dense(encoding_dim, name='encoding')(input_layer) # encoding layer\n",
    "decoding_layer = tf.keras.layers.Dense(output_dim, name='decoding')(encoding_layer) # decoding layer\n",
    "\n",
    "autoencoder = tf.keras.Model(input_layer, decoding_layer)\n",
    "autoencoder.compile(optimizer=optimizer, loss=loss)\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af08336b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set other parameters\n",
    "epochs=50\n",
    "batch_size=16\n",
    "shuffle=True\n",
    "validation_split=0.1\n",
    "verbose=0\n",
    "\n",
    "# early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, verbose=1)\n",
    "\n",
    "history = autoencoder.fit(X_scaled, X_scaled,\n",
    "                          epochs=epochs,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=shuffle,\n",
    "                          validation_split=validation_split,\n",
    "                          verbose=verbose)\n",
    "#                           callbacks=[early_stop])\n",
    "\n",
    "# Plot the loss \n",
    "plt.plot(history.history['loss'], color='#FF7E79',linewidth=3, alpha=0.5)\n",
    "plt.plot(history.history['val_loss'], color='#007D66', linewidth=3, alpha=0.4)\n",
    "plt.title('Model train vs Validation loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='best')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f733e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training loss:\", history.history['loss'][-1])\n",
    "print(\"Validation loss:\", history.history['val_loss'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ca036d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot3clusters(X, title, vtitle, target_names):\n",
    "    colors = ['#A43F98', '#5358E0', '#DE0202']\n",
    "    s = 50\n",
    "    alpha = 0.7\n",
    "    \n",
    "    plt.figure(figsize=(9, 7))\n",
    "    plt.grid(True)\n",
    "    for color, i, target_name in zip(colors, [0, 1, 2], target_names):\n",
    "        plt.scatter(X[y == i, 0], X[y == i, 1], color=color, alpha=alpha, s=s, label=target_name)\n",
    "   \n",
    "    plt.legend(loc='best', shadow=False, scatterpoints=1)\n",
    "    plt.title(title, fontsize=16, fontweight='bold')\n",
    "    \n",
    "    plt.text(0.5, -0.1, 'Principal Component 1', ha='center', fontsize=12, fontweight='bold', transform=plt.gca().transAxes)\n",
    "    plt.text(-0.1, 0.5, 'Principal Component 2', va='center', rotation='vertical', fontsize=12, fontweight='bold', transform=plt.gca().transAxes)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d17162",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = tf.keras.Model(input_layer, encoding_layer)\n",
    "encoded_data = encoder.predict(X_scaled)\n",
    "\n",
    "target_names = iris.target_names\n",
    "\n",
    "plot3clusters(encoded_data, 'Encoded data latent-space', 'dimension ', target_names);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f22aa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753dc187",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
